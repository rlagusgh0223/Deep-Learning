{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "심층 신경망",
      "provenance": [],
      "authorship_tag": "ABX9TyNekEynNpVrMu4ULmCJOiJf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfU7SPog-1oJ",
        "outputId": "c6144355-d8bc-4e71-e636-3268be200821"
      },
      "source": [
        "#2개의 층\n",
        "from tensorflow import keras\n",
        "(train_input, train_target), (test_input,test_target) =\\\n",
        "  keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)\n",
        "\n",
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
        "dense2 = keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "#심층 신경망 만들기\n",
        "model = keras.Sequential([dense1, dense2])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#층을 추가하는 다른 방법\n",
        "model = keras.Sequential([keras.layers.Dense(100,activation='sigmoid',input_shape=(784,),name='hidden'),\n",
        "                          keras.layers.Dense(10, activation='softmax',name='output')],name='패션 MNIST 모델')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100,activation='sigmoid',input_shape=(784,)))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)\n",
        "\n",
        "#렐루 함수\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) =\\\n",
        "  keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)\n",
        "\n",
        "model.evaluate(val_scaled, val_target)\n",
        "\n",
        "#옵티마이저\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)\n",
        "\n",
        "model.evaluate(val_scaled, val_target)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_59 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"패션 MNIST 모델\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden (Dense)               (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_61 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5626 - accuracy: 0.8106\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4065 - accuracy: 0.8536\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3731 - accuracy: 0.8650\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3499 - accuracy: 0.8746\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3339 - accuracy: 0.8801\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_10 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5399 - accuracy: 0.8113\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3963 - accuracy: 0.8574\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3566 - accuracy: 0.8708\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3323 - accuracy: 0.8813\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3188 - accuracy: 0.8858\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3642 - accuracy: 0.8798\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5321 - accuracy: 0.8150\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4004 - accuracy: 0.8575\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3567 - accuracy: 0.8705\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3295 - accuracy: 0.8780\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3096 - accuracy: 0.8870\n",
            "375/375 [==============================] - 1s 1ms/step - loss: 0.3420 - accuracy: 0.8757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34197551012039185, 0.8756666779518127]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}